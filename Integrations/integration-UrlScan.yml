commonfields:
  id: urlscan.io
  version: -1
name: urlscan.io
display: urlscan.io
category: Data Enrichment & Threat Intelligence
image: data:image/png;base64,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
description: Urlscan.io reputation
detaileddescription: |-
  This integration checks domain information from the urlscan.io Database.
  This is a free service with an API key required. contact urlscan.io to obtain one.
configuration:
- display: Server URL (e.g. https://urlscan.io/api/v1/)
  name: url
  defaultvalue: https://urlscan.io/api/v1/
  type: 0
  required: true
- display: API Key (needed only for submitting URLs for scanning)
  name: apikey
  defaultvalue: ""
  type: 4
  required: false
- display: Trust any certificate (unsecure)
  name: insecure
  defaultvalue: "false"
  type: 8
  required: false
- display: Use system proxy settings
  name: proxy
  defaultvalue: "true"
  type: 8
  required: false
script:
  script: |+
    '''IMPORTS'''
    import requests
    import json
    import time
    import collections
    from requests.utils import quote
    import datetime

    # disable insecure warnings
    requests.packages.urllib3.disable_warnings()

    '''GLOBAL VARS'''
    BASE_URL = demisto.params().get('url')
    APIKEY = demisto.params().get('apikey')
    INSECURE = demisto.params().get('insecure')
    PROXY = demisto.params().get('proxy')
    if not demisto.params().get('proxy', False) or demisto.params()['proxy'] == 'false':
        del os.environ['HTTP_PROXY']
        del os.environ['HTTPS_PROXY']
        del os.environ['http_proxy']
        del os.environ['https_proxy']


    '''HELPER FUNCTIONS'''
    def http_request(method, url_suffix, json=None):
        if method is 'GET':
            headers = {}
        elif method is 'POST':
            headers = {
                'API-Key': APIKEY,
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
        r = requests.request(
            method,
            BASE_URL + url_suffix,
            data=json,
            headers=headers
        )
        if r.status_code not in {200, 204}:
            return_error('Error in API call to URLScan.io [%d] - %s' % (r.status_code, r.reason))
        return r.json()


    def makehash():
        return collections.defaultdict(makehash)


    try:
        from Queue import Queue
    except ImportError:
        from queue import Queue


    def step_constant(step):
        return step


    def step_linear_double(step):
        return step * 2


    def is_truthy(val):
        return bool(val)


    def poll(target, step, args=(), kwargs=None, timeout=None, max_tries=None, check_success=is_truthy,
             step_function=step_constant, ignore_exceptions=(), poll_forever=False, collect_values=None, *a, **k):

        kwargs = kwargs or dict()
        values = collect_values or Queue()

        max_time = time.time() + timeout if timeout else None
        tries = 0

        last_item = None
        while True:

            try:
                val = target(*args, **kwargs)
                last_item = val
            except ignore_exceptions as e:
                last_item = e
            else:
                if check_success(val):
                    return val

            values.put(last_item)
            tries += 1
            if max_time is not None and time.time() >= max_time:
                demisto.results({
                    'Type': entryTypes['note'],
                    'ContentsFormat': formats['markdown'],
                    'Contents': 'The operation timed out. Please try again with a longer timeout period.',
                    'HumanReadable': 'The operation timed out. Please try again with a longer timeout period.'
                    })
            time.sleep(step)
            step = step_function(step)


    '''MAIN FUNCTIONS'''
    def urlscan_submit_command():
        submission_dict = {}
        if demisto.args().get('public') is 'public':
            submission_dict['public'] = 'on'
        submission_dict['url'] = demisto.args().get('url')
        sub_json = json.dumps(submission_dict)
        r = http_request('POST', 'scan/', sub_json)
        uuid = r['uuid']
        if demisto.args().get('timeout') is None:
            TIMEOUT = 60
        else:
            TIMEOUT = demisto.args().get('timeout')
        uri = BASE_URL+'result/{}'.format(uuid)

        ready = poll(
            lambda: requests.get(uri).status_code == 200,
            step=5,
            ignore_exceptions=(requests.exceptions.ConnectionError,),
            timeout=int(TIMEOUT)
        )

        if ready is True:
            response = http_request('GET', 'result/{}'.format(uuid))
            scan_lists = response['lists']
            scan_tasks = response['task']
            scan_page = response['page']
            scan_stats = response['stats']
            scan_meta = response['meta']

            ec = makehash()
            human_readable = makehash()

            if 'urls' in scan_lists:
                # ec['URL']['Data'] = scan_lists['urls']
                ec['URLScan']['URLs'] = scan_lists['urls']

            if 'ips' in scan_lists:
                ip_asn_MD = []
                ip_asn_ec = []
                ip_list = scan_lists['ips']
                asn_list = scan_lists['asns']
                ip_asn_dict = dict(zip(ip_list, asn_list))
                i = 1
                for k in ip_asn_dict:
                    v = ip_asn_dict[k]
                    ip_info = {
                        'Count': i,
                        'IP': k,
                        'ASN': v
                    }

                    ip_asn_MD.append(ip_info)
                    i = i + 1
                ec['URLScan']['RelatedIPs'] = ip_list
                ec['URLScan']['RelatedASNs'] = asn_list
                IP_HEADERS = ['Count', 'IP', 'ASN']

            if 'countries' in scan_lists:
                human_readable['Associated Countries'] = scan_lists['countries']
                ec['URLScan']['Countries'] = scan_lists['countries']
            if not None in scan_lists['hashes']:
                ec['URLScan']['iocs'] = scan_lists['hashes']
                human_readable['iocs'] = scan_lists['hashes']
            if 'domains' in scan_lists:
                ec['URLScan']['Subdomains'] = scan_lists['domains']
                human_readable['Subdomains'] = scan_lists['domains']
            if 'asn' in scan_page:
                ec['URLScan']['ASN'] = scan_page['asn']
            if 'malicious' in scan_stats:
                # ec['Malicious'] = scan_stats['malicious']
                # ec['URL']['Data'] =
                human_readable['Malicious'] = scan_stats['malicious']
                if int(scan_stats['malicious']) > 0:
                    ec['URL']['Data'] = demisto.args().get('url')
                    ec['URLScan']['Data'] = demisto.args().get('url')
                    ec['URL']['Malicious']['Vendor'] = 'urlscan.io'
                    ec['URLScan']['Malicious']['Vendor'] = 'urlscan.io'
                    ec['URL']['Malicious']['Description'] = 'Match found in Urlscan.io database'
                    ec['URLScan']['Malicious']['Description'] = 'Match found in Urlscan.io database'


            if 'url' in scan_meta['processors']['gsb']['data'] is None:
                mal_url_list = []
                matches = scan_meta['processors']['gsb']['data']['matches']
                for match in matches:
                    mal_url = match['threat']['url']
                    mal_url_list.append(mal_url)
                human_readable['Related Malicious URLs'] = mal_url_list

            if len(scan_meta['processors']['download']['data']) > 0:
                human_readable['File']['Hash'] = scan_meta['processors']['download']['data'][0]['sha256']
                ec['URLScan']['File']['Hash'] = scan_meta['processors']['download']['data'][0]['sha256']
                ec['File']['SHA256'] = scan_meta['processors']['download']['data'][0]['sha256']
                human_readable['File']['Name'] = scan_meta['processors']['download']['data'][0]['filename']
                ec['URLScan']['File']['FileName'] = scan_meta['processors']['download']['data'][0]['filename']
                ec['File']['Name'] = scan_meta['processors']['download']['data'][0]['filename']
                human_readable['File']['Size'] = scan_meta['processors']['download']['data'][0]['filesize']
                ec['URLScan']['File']['FileSize'] = scan_meta['processors']['download']['data'][0]['filesize']
                ec['File']['Size'] = scan_meta['processors']['download']['data'][0]['filesize']
                human_readable['File']['Type'] = scan_meta['processors']['download']['data'][0]['mimeType']
                ec['URLScan']['File']['FileType'] = scan_meta['processors']['download']['data'][0]['mimeType']
                ec['File']['Type'] = scan_meta['processors']['download']['data'][0]['mimeType']
                ec['File']['Hostname'] = demisto.args().get('url')

            if 'screenshotURL' in scan_tasks:
                human_readable['Screenshot'] = scan_tasks['screenshotURL']
                screen_path = scan_tasks['screenshotURL']
                response_img = requests.request("GET", screen_path)
                stored_img = fileResult('screenshot.png', response_img.content)

            if 'certificates' in scan_lists:
                cert_md = []
                certs = scan_lists['certificates']
                for x in certs:
                    valid_to = datetime.datetime.fromtimestamp(x['validTo']).strftime('%Y-%m-%d %H:%M:%S')
                    valid_from = datetime.datetime.fromtimestamp(x['validFrom']).strftime('%Y-%m-%d %H:%M:%S')
                    info = {
                        'Subject Name': x['subjectName'],
                        'Issuer': x['issuer'],
                        'Validity': "{} - {}".format(valid_to, valid_from)
                    }
                    cert_md.append(info)
                CERT_HEADERS = ['Subject Name', 'Issuer', 'Validity']
                if len(cert_md) > 0:
                    demisto.results({
                        'Type': entryTypes['note'],
                        'ContentsFormat': formats['markdown'],
                        'Contents': tableToMarkdown('Certificates',cert_md,CERT_HEADERS),
                        'HumanReadable': tableToMarkdown('Certificates',cert_md,CERT_HEADERS)
                        })
                ec['URLScan']['Certificates'] = certs
            human_readable['Effective URL'] = submission_dict['url']

            demisto.results({
                    'Type': entryTypes['note'],
                    'ContentsFormat': formats['markdown'],
                    'Contents': tableToMarkdown('{} - Scan Results'.format(submission_dict['url']), human_readable),
                    'HumanReadable': tableToMarkdown('{} - Scan Results'.format(submission_dict['url']), human_readable),
                    'EntryContext': ec
                    })
            if 'ips' in scan_lists:
                demisto.results({
                    'Type': entryTypes['note'],
                    'ContentsFormat': formats['markdown'],
                    'Contents': tableToMarkdown('IPs and ASNs',ip_asn_MD,IP_HEADERS),
                    'HumanReadable': tableToMarkdown('IPs and ASNs',ip_asn_MD,IP_HEADERS)
                    })
            if 'screenshotURL' in scan_tasks:
                demisto.results({
                    'Type': entryTypes['image'],
                    'ContentsFormat': formats['text'],
                    'File': stored_img['File'],
                    'FileID': stored_img['FileID'],
                    'Contents': ''
                    })



    def urlscan_search_command():
        HUMAN_READBALE_HEADERS = ['URL', 'Domain', 'IP', 'ASN', 'Scan ID', 'Scan Date', 'File']
        raw_query = demisto.args().get('url')
        query = quote(raw_query, safe='')
        r = http_request('GET', 'search/?q=page.url:"'+query+'"')

        res_dict = r['results'][0]
        res_tasks = res_dict['task']
        res_stats = res_dict['stats']
        res_page = res_dict['page']

        human_readable = makehash()
        ec = makehash()

        if 'files' in res_dict:
            human_readable['Hash'] = res_dict['files'][0]['sha256']
            ec['URLScan']['Hash'] = res_dict['files'][0]['sha256']
            ec['File']['SHA256'] = res_dict['files'][0]['sha256']
            human_readable['Name'] = res_dict['files'][0]['filename']
            ec['URLScan']['FileName'] = res_dict['files'][0]['filename']
            ec['File']['Name'] = res_dict['files'][0]['filename']
            human_readable['Size'] = res_dict['files'][0]['filesize']
            ec['URLScan']['FileSize'] = res_dict['files'][0]['filesize']
            ec['File']['Size'] = res_dict['files'][0]['filesize']
            human_readable['Type'] = res_dict['files'][0]['mimeType']
            ec['URLScan']['FileType'] = res_dict['files'][0]['mimeType']
            ec['File']['Type'] = res_dict['files'][0]['mimeType']
            ec['File']['Hostname'] = res_tasks['url']

        if 'url' in res_tasks:
            human_readable['URL'] = res_tasks['url']
            ec['URLScan']['URL'] = res_tasks['url']
        if 'domain' in res_page:
            human_readable['Domain'] = res_page['domain']
            ec['URLScan']['Domain'] = res_page['domain']
            ec['Domain']['Name'] = res_page['domain']
        if 'asn' in res_page:
            ec['URLScan']['ASN'] = res_page['asn']
            ec['IP']['ASN'] = res_page['asn']
            human_readable['ASN'] = res_page['asn']
        if 'ip' in res_page:
            ec['URLScan']['IP'] = res_page['ip']
            ec['IP']['Address'] = res_page['ip']
            human_readable['IP'] = res_page['ip']
        if '_id' in res_dict:
            ec['URLScan']['ScanID'] = res_dict['_id']
            human_readable['Scan ID'] = res_dict['_id']
        if 'time' in res_tasks:
            ec['URLScan']['ScanDate'] = res_tasks['time']
            human_readable['Scan Date'] = res_tasks['time']

        demisto.info(str(ec))

        demisto.results({
                    'Type': entryTypes['note'],
                    'ContentsFormat': formats['markdown'],
                    'Contents': tableToMarkdown('Query results for {}'.format(raw_query), human_readable, HUMAN_READBALE_HEADERS),
                    'HumanReadable': tableToMarkdown('Query results for {}'.format(raw_query), human_readable, HUMAN_READBALE_HEADERS, removeNull=True),
                    'EntryContext': ec
                    })



    if demisto.command() == 'test-module':
        demisto.results('ok')
        sys.exit(0)
    if demisto.command() == 'urlscan-submit':
        urlscan_submit_command()
        sys.exit(0)
    if demisto.command() == 'urlscan-search':
        urlscan_search_command()
        sys.exit(0)


  type: python
  commands:
  - name: urlscan-search
    arguments:
    - name: url
      required: true
      default: true
      description: Url to check
    outputs:
    - contextPath: URLScan.URL
      description: Bad URLs found
    - contextPath: URLScan.Domain
      description: Domain of the url scanned
    - contextPath: URLScan.ASN
      description: ASN of the URL scanned
    - contextPath: URLScan.IP
      description: IP of the url scanned
    - contextPath: URLScan.ScanID
      description: Scan ID for the URL scanned
    - contextPath: URLScan.ScanDate
      description: Latest scan date for the URL
    - contextPath: URLScan.Hash
      description: SHA256 of file scanned
    - contextPath: URLScan.FileName
      description: Filename of the file scanned
    - contextPath: URLScan.FileSize
      description: File size of the file scanned
    - contextPath: URLScan.FileType
      description: File type of the file scanned
    description: Check URL Reputation
  - name: urlscan-submit
    arguments:
    - name: url
      required: true
      default: true
      description: Url to scan
    - name: timeout
      description: How much seconds to wait to the scan id result
      defaultValue: "30"
    - name: public
      auto: PREDEFINED
      predefined:
      - public
      - private
      description: Does the submit will be public or private
      defaultValue: public
    outputs:
    - contextPath: URLScan.URLs
      description: Related URLs found from scanned URL
    - contextPath: URLScan.RelatedIPs
      description: Related IPs found for the URL scanned
    - contextPath: URLScan.RelatedASNs
      description: Related ASNs found for the URL scanned
    - contextPath: URLScan.Countries
      description: Associated countries for the URL scanned
    - contextPath: URLScan.iocs
      description: iocs found for the URL scanned
    - contextPath: URLScan.Subdomains
      description: Associated subdomains for the url scanned
    - contextPath: URLScan.ASN
      description: ASN of the URL scanned
    - contextPath: URLScan.Data
      description: URL of the file found
    - contextPath: URLScan.Malicious.Vendor
      description: Vendor reporting the malicious indicator for the file
    - contextPath: URLScan.Malicious.Description
      description: Description of the malicious indicator
    - contextPath: URLScan.File.Hash
      description: SHA256 of file found
    - contextPath: URLScan.File.FileName
      description: File name of file found
    - contextPath: URLScan.File.FileType
      description: File type of the file found
    - contextPath: URLScan.File.Hostname
      description: URL where the file was found
    - contextPath: URLScan.Certificates
      description: Certificates found for the URL scanned
    description: Submit an url to scan
  runonce: false
releaseNotes: Deprecated ip, url and file commands. Reformatted context outputs.
fromversion: 3.5.0
tests:
  - urlscan_malicious_Test
